# -*- coding: utf-8 -*-
"""Rock_Paper_Scissors.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_9XVEYCRg6nac-unX3b6OkDcOi3fr5OF
"""

import tensorflow_datasets as tfds
import tensorflow as tf
import numpy as np

from tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Input, BatchNormalization,Dropout,ReLU
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint
from tensorflow.keras.applications.vgg19 import VGG19
from tensorflow.keras.models import Model, load_model
from tensorflow.keras.activations import relu, softmax


#callbacks
es=EarlyStopping(monitor='val_loss',patience=5)
tb=TensorBoard(histogram_freq=1,log_dir='logs',update_freq='epoch')
checkpoint=ModelCheckpoint("weights.epoch:{epoch:02d}-val_accuracy:{val_accuracy:.2f}-val_loss{val_loss:.2f}.hdf5",monitor='val_accuracy',save_weights_only=True)

#load the dataset
(train_ds, test_ds), ds_info = tfds.load("rock_paper_scissors",split=['train','test'],batch_size=64,shuffle_files=True,as_supervised=True,with_info=True)



#normalize images
def normalize_img(image, label):
  image=tf.cast(image, dtype=float)/255.
  return(image, label)

train_ds=train_ds.map(normalize_img)
test_ds=test_ds.map(normalize_img)





#the images are of shape (300,300,3) and the labels are scalar
train_ds

#get the num of classes
ds_info.features['label']

input_size=(300,300,3)
batch_size=64
epochs=50,
num_classes=3




#download the vgg19 model and set all layers not trainable
vgg_model=VGG19(include_top=False,input_shape=(300,300,3))
vgg_model.trainable=False
vgg_model.summary()

#get the block4_pool layer and assign that to be the last layer 
last_layer = vgg_model.get_layer("block5_pool")
print('last layer output shape: ', last_layer.output_shape)
last_output = last_layer.output

#assign the last layer of the vgg network to be the input of our top layers
X=Flatten()(last_output)
X=Dense(units=256,activation="relu")(X)
X=Dense(units=64,activation="relu")(X)
X=Dropout(0.3)(X)
X=Dense(units=num_classes,activation="softmax")(X)

model=Model(vgg_model.input,X)
model.summary()

#compile the model with adam optimizer, loss function to be sparse_categorical_crossentropy
model.compile(optimizer="adam",metrics=['accuracy'],loss="sparse_categorical_crossentropy")

# Commented out IPython magic to ensure Python compatibility.
# %load_ext tensorboard

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir "logs"

#fit the model for 50 epochs
history=model.fit(train_ds,
                  epochs=10,
                  callbacks=[es,tb,checkpoint],
                  validation_data=test_ds)

#save the model
model.save("rock_paper_scissors_model.h5")


predicted=np.argmax(model.predict(test_ds.take(1)),axis=1)
predicted

#open cv experiment
# import cv2
# from google.colab.patches import cv2_imshow
# import matplotlib.pyplot as plt
# %matplotlib inline




